---
layout: default
title: CV of Your Name
---

	<div class="cv">
		<a href="#" class="download" title="Download CV as PDF">Download CV</a>			
					<h2>JIAQI (JACK) CHENG</h2>
					<address>
					<p>Wellington, New Zealand IN 6011</p>
					<abbr title="phone">P:</abbr> (64) 21-1127-135<br>
					<span class="obfuscate">jqcheng9413@yahoo.com</span>
					<a href="https://www.linkedin.com/in/jiaqicheng9413/">LinkedIn</a><br>
					<a href="https://github.com/jackson9413">GitHub</a>
					</address>

					<h3>SKILLS</h3>
					<p><strong>Power BI, SQL, Python, Java, R, AWS</strong></p>
					<h3>WORK EXPERIENCE</h3>
					<h4 id="company-name">Health Quality And Safety Commission</h4>
					<p id="job-title"><strong>Data Engineer</strong></p>
					<p id="job-responsibilities">Job Responsibilities</p>
					<p>
						<ul>
							<li> Develop ETL scripts in Python and R, visualise the data with Power BI, Jupyter Notebook, 
								Python Flask/Django frameworks, and R Shiny, and deploy machine learning and deep learning 
								models with Python scikit-learn and Keras/PyTorch libraries as well as applying natural 
								language processing to analyse text-descriptive data. </li>
							<li> Use MSSQL, PostgreSQL, MySQL to create databases, update databases, maintain databases, join 
								different tables, and create new tables, views, and functions in Windows and Linux operating systems.</li>
							<li> Work with data analysts, data scientists, special advisors to translate requirements for the design, 
								and implementation of internal process improvements: automating manual processes, optimizing data 
								delivery, and re-designing infrastructure for greater scalability.</li>
							<li> Create data tools for team members of data analytics and scientists to assist them in building and 
								optimising the products into innovative industry products.</li>
							<li> Assist various stakeholders (internal/external) with data-related technical issues and support their 
								data infrastructure needs.</li>
							<li> Report to different stakeholders like researchers, government officials, and data teams by using 
								different visualisation tools and write papers and publish dashboards to provide commercial insights. </li>
							<li> Create and maintain optimal data pipeline architecture and keep the data centralised but separated and secure.</li>
						</ul>
					</p>
					<h4 id="company-name">EPECentre at University of Canterbury</h4>
					<p id="job-title"><strong>Data Scientist Intern</strong></p>
					<p id="job-responsibilities">Job Responsibilities</p>
					<p>
						<ul>
							<li> Supported the researchers to manage the workflow with data science tools and pipelines. </li>
							<li> Performed data cleaning, transformation, statistics description with numpy, pandas and made 
								data visualisations with matplotlib, seaborn, plotly. </li>
							<li> Did linear regression analysis with scikit-learn and generated thousands of pseudo data based 
								on 60 samples of data in a controllable and automatic way with Python and R algorithms and models. </li>
							<li> Designed a 1D model to calculate the variables and exported the values to different folders by time points 
								with Matlab. </li>
							<li> Assist various stakeholders (internal/external) with data-related technical issues and support their 
								data infrastructure needs.</li>
							<li> Developed a 3D model to visualise the variables in an interactive and dynamic way and measured the effect 
								of the noise with different thresholds. </li>
						</ul>
					</p>					
					<h3>PROJECTS</h3>
					<h4 id="project-name">Pseudo sales data loaded to AWS S3</h4>
					<ul>
						<li>Launched AWS EC2 instances and configured the IAM role.</li>
						<li>Created Kinesis Firehose.</li>
						<li>Configured Kinesis Firehose to store the output in S3 bucket.</li>
						<li>Created configuration files in EC2 to connect Kinesis Firehose and wrote Python codes to read and write data.</li>
					</ul>
					<h4 id="project-name">Application of Google Cloud Geocoding and Natural Language Processing API</h4>
					<ul>
						<li>Created and configured projects in Google cloud.</li>
						<li>Launched Geocoding and Natural Language Processing API and created API keys.</li>
						<li>Applied Python “FuzzyWuzzy” tool to do fuzzy string matching to compare the original mess addresses with the 
							output addresses from Geocoding API.</li>
						<li>Used Natural Language Processing API to perform Syntax, Entity, and Sentiment analysis and developed Python codes
							to run the processes in an automatic and scalable way. </li>
					</ul>
					<h4 id="project-name">PySpark Song Recommendations</h4>
					<ul>
						<li>Used PySpark functions and sql queries to load the dataset, clean the data and extract features.</li>
						<li>Used logistic regression, linearSVC, GBTs to perform song multi-classification analysis</li>
						<li>Applied ALS algorithm to learn the latent factors.</li>
						<li>Measured the recommendation results with Precision@5, NDCG@10, and MAP.</li>
					</ul>
					<h3>EDUCATION</h3>
					<h4 id="school-name">University of Canterbury</h4>
					<p>Master of Applied Data Science, GPA 6.5/9</p>
					<h4 id="school-name">Jilin University</h4>
					<p>Bachelor of Science, GPA 3.6/4</p>
					<h3>CERTIFICATES</h3>
					<ul>
						<li>IBM Applied AI with DeepLearning</li>
						<li>IBM Advanced Machine Learning and Signal Processing</li>
						<li>IBM Fundamentals of Scalable Data Science</li>
						<li>AWS Fundamentals: Going Cloud-Native</li>
					</ul>
					<h3 id="organisation-name">ORGANIZATIONS</h3>
					<p>IT Professionals NZ (02/2020 - Present)</p>
					<h3>INTERESTS</h3>
					<ul>
						<li>Running</li>
						<li>Guitar</li>
						<li>Reading</li>
						<li>Singing</li>
					</ul>
	</div>
